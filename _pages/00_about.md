---
layout: about
permalink: /
title: <strong>HAMLETS (Human And Machine in-the-Loop Evaluation and Learning Strategies)</strong> 
description: Human involvement in AI system design, development, and evaluation is critical to ensure that the insights being derived are practical, and the systems built are meaningful, reliable, and relatable to those who need them. Humans play an integral role in all stages of machine learning development, be it during data generation, interactively teaching machines, or interpreting, evaluating and debugging models. With growing interest in such “human in the loop” learning, we aim to highlight new and emerging research opportunities for the ML community that arise from the evolving needs to design evaluation and training strategies for humans and models in the loop. 

profile:
  align: right
  image: 
  address: 
news: true
social: true
---
#### Special Focus: This year, the workshop aims to focus on emerging and underexplored areas of human- and model-in-the-loop learning, such as employing humans to seek richer forms of feedback for data than labels alone, learning from dynamic adversarial data collection with humans employed to find weaknesses in models, earning from human teachers instructing computers through conversation and/or demonstration, investigating the role of humans in model interpretability, and assessing social impact of ML systems. We aim to bring together interdisciplinary researchers from academia and industry to discuss major challenges, outline recent advances, and facilitate future research in these areas.

#### Topics of interest for submission include but are not limited to the following:

  <table style="background-color: #FAFAFA;">
        <col width="40">
        <col width="100">
        <tr style="border: none;">       
            <td style="border: none;">
            <b> <font size="+2">Active and Interactive Learning</font> </b>
            </td>
            <td style="border: none;">
            <i> Machine teaching, including instructable agents for real-world decision making (robotic systems, natural language processing, computer vision)</i>   
            </td>                        
        </tr>
        <tr style="border: none;">    
        <td style="border: none;">
            <b> <font size="+2">Interpretability</font></b> 
            </td>
            <td style="border: none;">
            <i> Role of humans in building trustworthy AI systems: model interpretability and algorithmic fairness.</i>
            </td>  
        </tr>
        <tr style="border: none;">
        <td style="border: none;">
            <b> <font size="+2">Human as Model Adversary</font></b>
            </td>
            <td style="border: none;">
            <i> Richer human feedback, probing weaknesses of machine learning models</i>
            </td>
        </tr>
        <tr style="border: none;">
        <td style="border: none;">
            <b> <font size="+2">System Design</font></b>
            </td>
            <td style="border: none;">
            <i> Design of creative interfaces for data annotation, data visualization, interactive learning</i>
            </td>
        </tr>
        <tr style="border: none;">
        <td style="border: none;">
            <b> <font size="+2">Model Evaluation</font></b>
            </td>
            <td style="border: none;">
            <i> Role of humans in evaluating model performance for generation, robustness to input</i>
            </td>
        </tr>
        <tr style="border: none;">
            <td style="border: none;">
            <b><font size="+2">Crowdsourcing</font></b>
            </td>
            <td style="border: none;">
            <i> Best practices for improving worker engagement, preventing annotationartifacts, maximizing crowd-sourced data quality and efficiency</i>
            </td>
        </tr>
  </table>   




<div style="line-height:40%;">
    <br>
</div>

Questions? Contact *hamlets.neurips2020@gmail.com*.



